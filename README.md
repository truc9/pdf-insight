# ü¶ôü¶ôü¶ô PDF Insight

Experiment project with LLM RAG using llama3 and langchain

<sub>‚ö†Ô∏è This project not supported upload file from UI yet, in order to load PDF, place PDF documents into directory `rag/tmp/docs` and load from UI</sub>

## Roadmap
- [x] Load PDFs from directory
- [x] Q&A with context from loaded PDFs
- [ ] Stream text to UI
- [ ] Format chat response
- [ ] Upload PDF from UI

## Screenshots

![alt text](./doc/sc1.png "Title")

![alt text](./doc/sc2.png "Title")

## Reference
- https://ollama.com/library/llama3
- https://python.langchain.com/docs/use_cases/question_answering

